{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TYwIL79-xXQJ"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/twelvelabs-io/twelvelabs-developer-experience/blob/main/quickstarts/1.0.0-beta/TwelveLabs_Quickstart_Embeddings.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in  Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmpYRcFNT30r"
   },
   "source": [
    "# Create embeddings\n",
    "\n",
    "This guide shows how to utilize the TwelveLabs Python SDK to create embeddings for your videos.\n",
    "\n",
    "## Key concepts\n",
    "\n",
    "- **Asset**: Your uploaded content\n",
    "- **Embedding**: Vector representation of your content.\n",
    "- **Embedding task**: An asynchronous operation for processing your content and creating embeddings. Contains a status and the resulting embeddings when complete.\n",
    "\n",
    "## How it works\n",
    "\n",
    "To create video embeddings, provide your video content to the platform. You can upload video files as assets, provide a publicly accessible URL, or use base64-encoded data.\n",
    "\n",
    "The upload method in this guide supports video files up to 4 hours. For details about the available upload methods and the corresponding limits, see the [Upload methods](https://docs.twelvelabs.io/docs/concepts/upload-methods) page.\n",
    "\n",
    "**Customize your embeddings**\n",
    "\n",
    "You can customize your embeddings in the following ways:\n",
    "- Specify the types of embeddings you wish to generate:\n",
    "    - **Visual**: Based on visual content\n",
    "    - **Audio**: Based on audio content, excluding spoken words\n",
    "    - **Transcription**: Based on spoken words extracted from the audio track\n",
    "- Choose the embedding scope: clip (per segment) or asset (entire video)\n",
    "- Define how the platform divides your video into segments: dynamic (scene-based) or fixed (time-based)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "- To use the platform, you need an API key:\n",
    "  1. If you don't have an account, [sign up](https://playground.twelvelabs.io/) for a free account. No credit card is required to use the Free plan. This plan allows you to index up to 600 minutes of videos, which is sufficient for a small project.\n",
    "  2. Go to the [API Keys](https://playground.twelvelabs.io/dashboard/api-keys) page.\n",
    "  3. If you need to create a new key, select the **Create API Key** button. Enter a name and set the expiration period. The default is 12 months.\n",
    "  4. Select the **Copy** icon next to your key to copy it to your clipboard.\n",
    "- Your files must meet the [format requirements](https://docs.twelvelabs.io/docs/concepts/models/marengo#input-requirements).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the TwelveLabs Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install twelvelabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from twelvelabs import (\n",
    "    TwelveLabs,\n",
    "    VideoInputRequest,\n",
    "    MediaSource,\n",
    "    # For dynamic segmentation uncomment the next two lines:\n",
    "    # VideoSegmentation_Dynamic,\n",
    "    # VideoSegmentationDynamicDynamic,\n",
    "    # For fixed segmentation uncomment the next two lines:\n",
    "    # VideoSegmentation_Fixed,\n",
    "    # VideoSegmentationFixedFixed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure your API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab, store your API key as a Secret named `TL_API_KEY`. If you don't know how to create a Colab Secret, see https://medium.com/@parthdasawant/how-to-use-secrets-in-google-colab-450c38e3ec75.\n",
    "\n",
    "from google.colab import userdata\n",
    "TL_API_KEY = userdata.get('TL_API_KEY')\n",
    "\n",
    "# For other Python environments, you can use environment variables\n",
    "# TL_API_KEY = os.environ.get('TL_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhXzSOCgUdmv"
   },
   "source": [
    "## Upload a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elAj0cm1Upaa",
    "outputId": "3592ee9f-7037-4025-b201-45c93e5e901a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created asset: id=695e214e76cbe75a28db2bd5\n"
     ]
    }
   ],
   "source": [
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "\n",
    "asset = client.assets.create(\n",
    "    method=\"url\",\n",
    "    url=\"<YOUR_VIDEO_URL>\" # Example: https://github.com/twelvelabs-io/twelvelabs-developer-experience/raw/refs/heads/main/quickstarts/steve_jobs_introduces_iphone_in_2007.mp4\n",
    "    # Or use method=\"direct\" and file=open(\"<PATH_TO_VIDEO_FILE>\", \"rb\") to upload a file from the local file system\n",
    ")\n",
    "print(f\"Created asset: id={asset.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process your video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = client.embed.v_2.tasks.create(\n",
    "    input_type=\"video\",\n",
    "    model_name=\"marengo3.0\",\n",
    "    video=VideoInputRequest(\n",
    "        media_source=MediaSource(\n",
    "            asset_id=asset.id,\n",
    "            # url=\"<YOUR_VIDEO_URL>\",\n",
    "            # base_64_string=\"<BASE_64_ENCODED_DATA>\",\n",
    "        ),\n",
    "        # start_sec=0,\n",
    "        # end_sec=10,\n",
    "        # embedding_option=[\"visual\", \"audio\", \"transcription\"],\n",
    "        # embedding_scope=[\"clip\",\"asset\"]\n",
    "        # For dynamic segmentation:\n",
    "        # segmentation=VideoSegmentation_Dynamic(\n",
    "        #     dynamic=VideoSegmentationDynamicDynamic(\n",
    "        #         min_duration_sec=3  # Minimum segment duration in seconds\n",
    "        #     )\n",
    "        # ),\n",
    "        # For fixed segmentation:\n",
    "        # segmentation=VideoSegmentation_Fixed(\n",
    "        #     fixed=VideoSegmentationFixedFixed(\n",
    "        #         duration_sec=5  # Exact segment duration in seconds\n",
    "        #     )\n",
    "        # ),\n",
    "    ),\n",
    ")\n",
    "print(f\"Task ID: {task.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor the status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    task = client.embed.v_2.tasks.retrieve(task_id=task.id)\n",
    "    if task.status == \"ready\":\n",
    "        print(f\"Task completed\")\n",
    "        break\n",
    "    elif task.status == \"failed\":\n",
    "        print(\"Task failed\")\n",
    "        break\n",
    "    else:\n",
    "        print(\"Task still processing...\")\n",
    "        time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"EMBEDDINGS SUMMARY: {len(task.data)} total embeddings\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "for idx, embedding_data in enumerate(task.data, 1):\n",
    "    print(f\"[{idx}/{len(task.data)}] {embedding_data.embedding_option.upper()} | {embedding_data.embedding_scope.upper()}\")\n",
    "    print(f\"├─ Time range: {embedding_data.start_sec}s - {embedding_data.end_sec}s\")\n",
    "    print(f\"├─ Dimensions: {len(embedding_data.embedding)}\")\n",
    "    print(f\"└─ First 10 values: {embedding_data.embedding[:10]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "For a comprehensive guide on creating video and other types of embeddings, see the [Create embeddings](https://docs.twelvelabs.io/docs/guides/create-embeddings) page."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
