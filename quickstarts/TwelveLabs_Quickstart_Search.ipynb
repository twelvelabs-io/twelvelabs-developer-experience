{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMOpOuAtwwFo"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/twelvelabs-io/twelvelabs-developer-experience/blob/main/quickstarts/1.0.0-beta/TwelveLabs_Quickstart_Search.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in  Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VmpYRcFNT30r"
   },
   "source": [
    "# Search\n",
    "\n",
    "This guide shows how to utilize the TwelveLabs Python SDK for searching within your video content.\n",
    "\n",
    "## Key concepts\n",
    "\n",
    "- **Index**: A container that organizes your video content\n",
    "- **Asset**: Your uploaded file\n",
    "- **Indexed asset**: A video that has been indexed and is ready for downstream tasks\n",
    "\n",
    "## How it works\n",
    "\n",
    "To search your videos, you must first upload and index them. The platform indexes videos asynchronously. After indexing completes, you can search your videos. Search results show video segments that match your search terms.\n",
    "\n",
    "The upload method in this guide allows for files up to 4 GB when using publicly accessible URLs and 200 MB for local files. For details about the available upload methods and the corresponding limits, see the [Upload methods](https://docs.twelvelabs.io/docs/concepts/upload-methods) page.\n",
    "\n",
    "\n",
    "**Types of search queries**\n",
    "\n",
    "The platform supports three types of search queries:\n",
    "- **Text queries**: Search using natural language descriptions of visual elements, actions, sounds, or spoken words\n",
    "- **Image queries**: Search using images to find visually similar content in your videos\n",
    "- **Composed queries**: Combine text descriptions with images for more precise results (Marengo 3.0 only)\n",
    "\n",
    "For guidance on choosing the correct query type, see the [Search with text, image, and composed queries](https://docs.twelvelabs.io/docs/guides/search/search-with-text-and-image-queries) page.\n",
    "\n",
    "**Search scope**\n",
    "\n",
    "You can search within a single index per request. You cannot search at the video level or across multiple indexes simultaneously.\n",
    "\n",
    "**Customize your search**\n",
    "\n",
    "You can customize your search in the following ways:\n",
    "- Specify which modalities to use: visual, audio, or transcription (spoken words)\n",
    "- Choose how to combine modalities: use the or or and operators\n",
    "- For searches within spoken words, select the match type: lexical, semantic, or both"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "Before you begin, ensure the following prerequisites are met:\n",
    "\n",
    "- [Sign up](https://playground.twelvelabs.io/) for a free account and obtain your API key from the [API Key](https://playground.twelvelabs.io/dashboard/api-key) page. No credit card is required to use the Free plan. This plan allows you to index up to 600 minutes of videos, which is sufficient for a small project.\n",
    "- Your video files must meet the [format requirements](https://docs.twelvelabs.io/docs/concepts/models/marengo#input-requirements).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the TwelveLabs Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install twelvelabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from twelvelabs import TwelveLabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure your API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Google Colab, store your API key as a Secret named `TL_API_KEY`. If you don't know how to create a Colab Secret, see https://medium.com/@parthdasawant/how-to-use-secrets-in-google-colab-450c38e3ec75.\n",
    "\n",
    "from google.colab import userdata\n",
    "TL_API_KEY = userdata.get(\"TL_API_KEY\")\n",
    "\n",
    "# For other Python environments, you can use environment variables\n",
    "# TL_API_KEY = os.environ.get('TL_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an index\n",
    "\n",
    "Indexes store and organize your video data, allowing you to group related videos. This guide shows how to create one, but you can also use an existing index. See the [Indexes](https://docs.twelvelabs.io/docs/concepts/indexes) page for more details on creating an index and specifying the model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = TwelveLabs(api_key=TL_API_KEY)\n",
    "\n",
    "index = client.indexes.create(\n",
    "    index_name=\"<YOUR_INDEX_NAME>\",\n",
    "    models=[{\"model_name\": \"marengo3.0\", \"model_options\": [\"visual\", \"audio\"]}]\n",
    ")\n",
    "if not index.id:\n",
    "    raise RuntimeError(\"Failed to create an index.\")\n",
    "print(f\"Created index: id={index.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asset = client.assets.create(\n",
    "    method=\"url\",\n",
    "    url=\"<YOUR_VIDEO_URL>\" # Example: https://github.com/twelvelabs-io/twelvelabs-developer-experience/raw/refs/heads/main/quickstarts/steve_jobs_introduces_iphone_in_2007.mp4\n",
    "    # Or use method=\"direct\" and file=open(\"<PATH_TO_VIDEO_FILE>\", \"rb\") to upload a file from the local file system\n",
    ")\n",
    "print(f\"Created asset: id={asset.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index your video\n",
    "\n",
    "Index your video by adding the asset created in the previous step to an index. This operation is asynchronous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_asset = client.indexes.indexed_assets.create(\n",
    "    index_id=index.id,\n",
    "    asset_id=asset.id,\n",
    "    # enable_video_stream=True\n",
    ")\n",
    "print(f\"Created indexed asset: id={indexed_asset.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitor the indexing process\n",
    "\n",
    "The platform requires some time to index videos. Check the status of the indexing process until itâ€™s completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Waiting for indexing to complete.\")\n",
    "while True:\n",
    "    indexed_asset = client.indexes.indexed_assets.retrieve(\n",
    "        index_id=index.id,\n",
    "        indexed_asset_id=indexed_asset.id\n",
    "    )\n",
    "    print(f\"  Status={indexed_asset.status}\")\n",
    "    if indexed_asset.status == \"ready\":\n",
    "        print(\"Indexing complete!\")\n",
    "        break\n",
    "    elif indexed_asset.status == \"failed\":\n",
    "        raise RuntimeError(\"Indexing failed\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform searches\n",
    "\n",
    "Perform a search within your index using a text or image query or a combination of both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using text queries**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = client.search.query(\n",
    "    index_id=index.id,\n",
    "    query_text=\"<YOUR_QUERY>\", # Example: \"Steve Jobs\"\n",
    "    search_options=[\"visual\", \"audio\"]\n",
    "    # operator=\"or\" # Optional: Use \"and\" to find segments matching all modalities\n",
    "    # transcription_options=[\"lexical\", \"semantic\"]  # Optional: Control transcription matching (Marengo 3.0 only, requires \"transcription\" in search_options)\n",
    ")\n",
    "\n",
    "print(\"\\nSearch results:\")\n",
    "print(\"Each result shows a video clip that matches your query:\\n\")\n",
    "for i, clip in enumerate(search_results):\n",
    "    print(f\"Result {i + 1}:\")\n",
    "    print(f\"  Video ID: {clip.video_id}\")  # Unique identifier of the video\n",
    "    print(f\"  Rank: {clip.rank}\")  # Relevance ranking (1 = most relevant)\n",
    "    print(f\"  Time: {clip.start}s - {clip.end}s\")  # When this moment occurs in the video\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using image queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = client.search.query(\n",
    "    index_id=index.id,\n",
    "    search_options=[\"visual\"],\n",
    "    query_media_type=\"image\",\n",
    "    query_media_url=\"<YOUR_IMAGE_URL>\"\n",
    "    # Or for a local file: query_media_file =open(\"<PATH_TO_IMAGE_FILE>\", \"rb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using composed text and image queries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = client.search.query(\n",
    "    index_id=index.id,\n",
    "    search_options=[\"visual\"],\n",
    "    query_text=\"<YOUR_QUERY>\",\n",
    "    query_media_type=\"image\",\n",
    "    query_media_url=\"<YOUR_IMAGE_URL>\"\n",
    "    # Or for a local file: query_media_file =open(\"<PATH_TO_IMAGE_FILE>\", \"rb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "For a comprehensive guide, see the [Search](https://docs.twelvelabs.io/docs/guides/search) page."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
